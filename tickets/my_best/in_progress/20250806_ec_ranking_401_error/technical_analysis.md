---
file_type: "technical_analysis"
ticket_id: "TKT-20250806-001"
analyst: "技術チーム"
analysis_date: "2025-08-06"
complexity: "高"
tech_category: "データ抽出・構造化・自動化"
estimated_development_hours: 16
priority: "緊急"
deadline: "2025-08-08"
issued_at: "2025-08-06"
due_date: "2025-08-08"
ball_holder: "先方"
---

# 技術的分析: ECスペック抽出機能開発

## 概要分析

### 問題の本質
1. **401エラー問題**: 緊急（ブロッカー）
2. **スペック抽出最適化**: 戦略的機能開発（週20本制作体制への基盤）

## 1. 401エラー問題の技術分析

### 根本原因候補
1. **認証トークン期限切れ**
   - APIキー、セッション情報の失効
   - 解決時間: 30分〜1時間

2. **レート制限・ボット検出**
   - 過去事例（TKT-20250803-003）と同様パターン
   - 解決時間: 2-4時間（ヘッダー調整・間隔制御）

3. **ECサイト側仕様変更**
   - セキュリティポリシー強化
   - 解決時間: 4-8時間（代替手法実装）

### 即時対応策
- 過去解決事例の適用（User-Agent、ヘッダー設定）
- 異なる時間帯での再実行テスト
- 代替APIエンドポイントの検証

## 2. スペック抽出機能の技術設計

### 要求仕様の構造化

#### 入力
- 複数商品ページのURL配列
- 商品カテゴリ情報（液タブ、犬用クールネック、皮膜式アイプチ等）
- **新規追加**: 商材定義情報（冷却方式分類等）

#### 出力（一覧表形式）
```
| グルーピングカテゴリ | 項目 | 値 | 商品URL |
|---|---|---|---|
| 表示性能 | 画面サイズ | 13.3インチ | https://... |
| 表示性能 | 解像度 | 1920×1080 | https://... |
| 接続性 | 入出力端子 | USB-C, HDMI | https://... |
```

### アーキテクチャ設計

#### 推奨アプローチ：パイプライン型処理
```mermaid
graph LR
A[商品URL配列] --> B[並列スペック抽出]
B --> C[データ正規化]
C --> D[LLMグルーピング]
D --> E[一覧表生成]
```

#### 1. 並列スペック抽出ステージ
```javascript
// 疑似コード
const extractSpecs = async (urls) => {
  return await Promise.all(
    urls.map(url => extractSpecFromPage(url))
  );
};
```

#### 2. データ正規化ステージ
- 各商品のスペック情報を共通フォーマットに変換
- 欠損データの補完
- 単位統一（cm → mm等）

#### 3. LLMグルーピングステージ
```yaml
prompt_template: |
  以下のスペック項目を意味のあるカテゴリでグルーピングしてください：
  
  項目: {spec_items}
  商品カテゴリ: {product_category}
  商材定義: {product_definition}
  
  グルーピング例（商品カテゴリ別）:
  
  # 液タブ系
  - 表示性能: 画面サイズ、解像度、輝度
  - 接続性: 入出力端子、無線接続  
  - 電源: 電源方式、バッテリー、消費電力
  
  # 犬用クールネック系
  - 冷却方式: 保水・気化熱、吸熱ゲル、PCM相変化素材
  - 材質・構造: 布製、メッシュ、ゲルパック構造
  - 使用方法: 水浸し、冷凍庫、常温使用
  - サイズ・対応: 首回りサイズ、犬種対応
  
  # 皮膜式アイプチ系  
  - 皮膜形成: 膜の厚さ、乾燥時間、持続力
  - 成分・材質: 主成分、アレルギー対応
  - 使用感: 仕上がり、除去方法
```

#### 4. 一覧表生成ステージ
- Markdown/HTML/CSV形式での出力
- URL付きでトレーサビリティ確保
- 統計情報の付加（傾向分析）

### 従来方法の問題点分析

#### 現在の問題
```mermaid
graph TD
A[各商品] --> B[個別スペック抽出]
B --> C[結果統合]
C --> D[分離処理]
D --> E[表形式変換]
```

#### 問題点
1. **処理の複雑性**: 結合→分離の冗長フロー
2. **データ整合性**: 統合時の情報欠損リスク
3. **保守性**: ノード数が多く複雑化

### 最適化提案

#### 新アーキテクチャ
```mermaid
graph LR
A[商品URL配列] --> B[バッチスペック抽出]
B --> C[構造化データ生成]
C --> D[一覧表出力]
```

#### 技術的メリット
1. **シンプル化**: ノード数 50% 削減
2. **性能向上**: 並列処理による高速化
3. **データ品質**: 一貫した構造化処理
4. **拡張性**: 新商品カテゴリ対応容易

## 3. 実装計画

### Phase 1: 緊急対応（0.5日）
- [ ] 401エラーの根本原因特定・修正
- [ ] 既存スペック抽出機能の安定化

### Phase 2: コア機能開発（1.5日）
- [ ] 並列スペック抽出エンジン
- [ ] データ正規化ロジック
- [ ] LLMグルーピング機能

### Phase 3: UI/出力最適化（0.5日）
- [ ] 一覧表フォーマット実装
- [ ] URL付きトレーサビリティ
- [ ] 統計情報付加

### Phase 4: 統合テスト（0.5日）
- [ ] エンドツーエンドテスト
- [ ] 性能検証（週20本対応）
- [ ] エラーハンドリング強化

## 4. 技術的課題とリスク

### 高リスク項目
1. **スペック抽出精度**
   - 商品ページ構造の違い
   - **新規**: 商品カテゴリごとのスペック表記揺れ
   - 軽減策: 複数パターン対応、商材定義活用、フォールバック処理

2. **LLMグルーピング品質**
   - カテゴリ分類の一貫性
   - **改善**: 商材定義による分類精度向上
   - 軽減策: プロンプト最適化、カテゴリ別サンプル学習

3. **性能要件（週20本）**
   - 大量処理時の安定性
   - 軽減策: バッチサイズ調整、エラーリトライ

### 中リスク項目
1. **データフォーマット統一**
   - 単位系・表記揺れ
   - 軽減策: 正規化辞書、バリデーション強化

## 5. 成功指標（KPI）

### 機能要件
- [ ] 4カラム（カテゴリ・項目・値・URL）完全対応
- [ ] 商品数10〜50件での安定動作
- [ ] 処理時間: 5分以内/10商品

### 品質要件
- [ ] スペック抽出精度: 95%以上
- [ ] グルーピング一貫性: 90%以上
- [ ] エラー率: 5%未満

### 業務要件
- [ ] 週20本制作ワークフローへの統合完了
- [ ] 人的工数50%削減（編集作業簡素化）

## 6. 商材定義の活用効果

### 追加設定値による改善点
1. **グルーピング精度向上**
   - 犬用クールネック: 3つの冷却方式による自動分類
   - 技術的特徴を基にした合理的なカテゴリ生成

2. **スペック項目予測**
   - 商材定義から重要スペック項目を予測
   - 抽出対象の優先順位付けが可能

3. **表記揺れ対応**
   - 代替表記（ネッククーラー等）の自動認識
   - 同義語辞書の自動構築

### 技術的なアクション項目
- [ ] **皮膜式アイプチの定義完成版確認**（途中で切れている）
- [ ] **テンプレートノード消去**（稼働中の口コミ部分）
- [ ] 商材定義のデータベース化・検索機能実装

## 7. 次期発展計画

### 構成作成との連携（将来）
- スペックデータの構成案への自動反映
- **商材定義 × ニーズ × スペック** の3軸掛け合わせロジック
- 見出し自動生成機能

### 商材拡張対応
- 新商材の定義追加によるスペック抽出パターン拡張
- カテゴリ別最適化プロンプトの自動生成

この技術分析に基づき、商材定義を活用した高精度なスペック抽出機能により今週末の完成を目指します。

## 設計更新（2025-08-08）

### アーキテクチャ変更
- FireCrawlをHTTPリクエストへ置換（Amazon等での失敗低減）。
- ECサイト処理ループでURL収集→配列化→後段でLLMイテレーション（スペック/口コミ）→コードノードで統合整形。

### モデル選定
- 口コミ抽出は大規模出力対応のため Gemini/GPT を採用（Claudeは出力上限で不利）。
- スペック抽出は温度低め・厳格抽出指向の設定。

### スループット/上限対策
- `unique_urls[:N]`でイテレーション件数を制御（初期N=10目安）。
- 並列数は5程度（10は失敗率上昇）。
- コードノード約8万文字上限を越えないようN/出力密度を調整。

### 次アクション
- テンプレートノードの削除（依頼対応）。
- 表正規化・単位統一・エラー処理の強化。
- 代表20商品の性能検証とパラメータ固定化。
