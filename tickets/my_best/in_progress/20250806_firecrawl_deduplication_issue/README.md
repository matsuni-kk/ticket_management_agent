---
file_type: "ticket_summary"
ticket_id: "TKT-20250806-002"
title: "Fire Crawl商品重複除去の入力値制限問題"
company: "My Best"
reporter: "Kaho Nagaso"
create_date: "2025-08-06"
update_date: "2025-08-06"
status: "対応中"
category: "技術的問題"
priority: "中"
assigned_to: "技術チーム"
estimated_hours: 4
related_tickets: ["TKT-20250803-004", "TKT-20250806-001"]
technical_constraint: "LLM入力値制限（649,032 tokens）"
cost_impact: "$0.83 per execution"
issued_at: "2025-08-06"
due_date: ""
ball_holder: "当方"
---

# チケット: Fire Crawl商品重複除去の入力値制限問題

## 基本情報
- **チケットID**: TKT-20250806-002
- **タイトル**: Fire Crawl商品重複除去の入力値制限問題
- **会社名**: My Best
- **報告者**: Kaho Nagaso
- **作成日**: 2025-08-06
- **ステータス**: 対応中
- **優先度**: 中

## 問題概要

### 技術的制約
**LLM入力値制限**: 649,032 tokens（膨大なデータ量でLLM処理不可）

### システム構成
- **基盤**: Fire Crawl版商品ピックアップDify
- **処理対象**: ECサイトから取得した商品データ
- **課題**: 重複商品の統合処理

### 試行した解決策
1. **コードベース重複除去**: 実装困難
2. **LLMベース重複除去**: 入力値制限でブロック

## 技術分析

### データ量の問題
```
プロンプトトークン: 649,032 tokens
完了トークン: 1,773 tokens  
総トークン: 650,805 tokens
処理コスト: $0.82902 USD
処理時間: 112秒
```

### 期待する処理結果
商品重複除去後のデータ構造:
```javascript
{
  final_products: [
    {
      product_name: "統合後の代表商品名",
      urls: ["重複商品のURL配列"],
      amazon_rank: "最良順位",
      rakuten_rank: "最良順位", 
      yahoo_rank: "最良順位",
      kakaku_rank: "最良順位"
    }
  ]
}
```

## 関連チケットとの連携

### TKT-20250803-004との関連
- **同一報告者**: Kaho Nagaso
- **同一システム**: Dify・EC順位システム  
- **解決実績**: 商品データ処理の成功事例
- **活用可能**: 既存の技術的知見

### TKT-20250806-001との関連
- **共通課題**: 大量データの効率処理
- **技術的相乗効果**: バッチ処理・並列化手法の応用可能性

## 解決アプローチ案

### 1. データ分割処理（推奨）
**コンセプト**: 大量データを小さなバッチに分割
```
Step 1: データを適切なサイズに分割（例：100商品ずつ）
Step 2: 各バッチで重複除去実行  
Step 3: バッチ間での最終統合処理
Step 4: 全体の整合性検証
```

### 2. ハイブリッドアプローチ
**コンセプト**: コード前処理 + LLM精密化
```
Step 1: コードベースで明白な重複を事前除去
Step 2: 残った疑似重複をLLMで精密判定
Step 3: 最終統合処理
```

### 3. ストリーミング処理
**コンセプト**: 逐次処理による制限回避
```
Step 1: 商品データをストリーミングで取得
Step 2: リアルタイム重複検出・除去
Step 3: バッファリング機能で効率化
```

## 実装優先度

### 高優先（即座対応）
- [ ] データ分割サイズの最適化検証
- [ ] バッチ処理の実装・テスト
- [ ] トークン使用量の監視機能

### 中優先（1週間以内）
- [ ] ハイブリッドアプローチの設計
- [ ] コードベース前処理の実装
- [ ] 処理コスト最適化

### 低優先（将来対応）
- [ ] ストリーミング処理の検討
- [ ] スケーラビリティ向上
- [ ] 自動バッチサイズ調整

## 期待される改善効果

### 処理効率化
- **トークン使用量**: 90%削減（649K → 65K tokens想定）
- **処理コスト**: 90%削減（$0.83 → $0.08想定）
- **処理時間**: 80%削減（112秒 → 22秒想定）

### 品質向上
- **重複除去精度**: コード+LLMで95%以上
- **データ整合性**: バッチ間検証で保証
- **スケーラビリティ**: 商品数増加に対応

この技術的制約を解決することで、Fire Crawl商品ピックアップDifyの実用性が大幅に向上します。

## 原因
- LLM入力値制限により、重複除去対象データを一括で与えるとプロンプトが数十万トークンに達して処理不可/非効率となる。

## 解決策（暫定方針）
1) 分割バッチ処理: データを100件などのバッチに分割し、各バッチで重複除去を実行。
2) ハイブリッド: コード前処理で明白重複を事前除去→残りをLLMで精密判定→最終統合。
3) ストリーミング（検討）: データを逐次処理し、リアルタイムに重複検出・除去。
4) 管理: トークン使用量とコスト/レイテンシを監視し、バッチサイズ/閾値を最適化。
